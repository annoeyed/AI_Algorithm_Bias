{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI 편향성 분석 및 완화 실험\n",
        "\n",
        "이 노트북은 FairFace 데이터셋을 사용하여 AI 모델의 편향성을 다각도로 분석하고, 이를 완화하기 위한 기법을 실험하는 과정을 담고 있습니다.\n",
        "\n",
        "**실험 목표:**\n",
        "1.  **Baseline 모델 구축**: 실제 이미지 데이터로 딥러닝 모델(ResNet18)을 학습하고, 기본적인 성능과 그룹별 공정성 지표를 측정합니다.\n",
        "2.  **Micro-Bias Sensitivity Curve (편향 민감도 곡선) 분석**: 데이터셋에 의도적으로 미세한 편향을 주입했을 때, 모델의 성능과 공정성 지표가 얼마나 민감하게 변하는지 측정하고 시각화합니다.\n",
        "3.  **Over-Correction Damage Index (ODI, 과보정 피해 지수) 계산**: 공정성 제약을 적용했을 때 발생하는 성능 저하(Trade-off)를 정량적으로 분석합니다.\n",
        "4.  **Hidden Subgroup Discovery (잠복 하위집단 탐지)**: 전체적으로는 공정해 보이는 모델이 특정 하위집단(e.g., 특정 인종의 특정 연령대)에서 보이는 잠재적 편향을 탐지합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 단계 1: 실험 환경 설정 및 데이터셋 준비\n",
        "\n",
        "이 단계에서는 실험에 필요한 라이브러리를 임포트하고, FairFace 데이터셋을 불러올 준비를 합니다. 실제 이미지 데이터를 모델이 학습할 수 있는 형태(Tensor)로 변환하는 PyTorch `Dataset`과 `DataLoader`를 정의합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0+cu128\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# === 1.1 라이브러리 임포트 ===\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import copy\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "\n",
        "# 경고 메시지 무시\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Matplotlib 스타일 설정\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "Target Attribute: gender\n",
            "Sensitive Attribute: race\n"
          ]
        }
      ],
      "source": [
        "# === 1.2 주요 설정 (Configuration) ===\n",
        "# 데이터셋 경로\n",
        "DATA_DIR = './data/fairface'\n",
        "TRAIN_LABEL_FILE = os.path.join(DATA_DIR, 'fairface_label_train.csv')\n",
        "VAL_LABEL_FILE   = os.path.join(DATA_DIR, 'fairface_label_val.csv')\n",
        "\n",
        "# 이미지 폴더(train/val)도 명시\n",
        "TRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train')\n",
        "VAL_IMG_DIR   = os.path.join(DATA_DIR, 'val')\n",
        "\n",
        "# 실험 속성\n",
        "TARGET_ATTR = 'gender'   # 예측 대상 속성 ('gender' 또는 'race')\n",
        "SENSITIVE_ATTR = 'race'  # 민감 속성 (편향 분석 기준)\n",
        "\n",
        "# 학습 하이퍼파라미터 (WSL/CPU 안정 위주)\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 0                 # WSL/Windows에선 0이 가장 안정적\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 디버그용: 작은 서브셋으로 빠르게 파이프라인 확인\n",
        "FAST_DEBUG = False              # 필요하면 True로 켜기\n",
        "DEBUG_SAMPLES_TRAIN = 2000\n",
        "DEBUG_SAMPLES_VAL   = 400\n",
        "\n",
        "# 결과 저장\n",
        "MODEL_SAVE_PATH = 'best_baseline_model.pth'\n",
        "RESULTS_DIR = 'results'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Target Attribute: {TARGET_ATTR}\")\n",
        "print(f\"Sensitive Attribute: {SENSITIVE_ATTR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 1.3 FairFace 데이터셋 클래스 정의 ===\n",
        "class FairFaceDataset(Dataset):\n",
        "    \"\"\"FairFace 이미지 데이터셋을 위한 PyTorch Dataset 클래스\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_root,\n",
        "        label_file,\n",
        "        file_col=\"file\",\n",
        "        gender_col=\"gender\",\n",
        "        race_col=\"race\",\n",
        "        transform=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_root (str): 이미지가 들어있는 디렉터리 (train/ 또는 val/).\n",
        "            label_file (str): 라벨 CSV 경로.\n",
        "        \"\"\"\n",
        "        self.img_root = Path(img_root).resolve()\n",
        "        # CSV가 'train/...' 또는 'val/...'를 포함할 수 있으므로 루트 보정\n",
        "        self.data_root = self.img_root.parent if self.img_root.name in (\"train\", \"val\") else self.img_root\n",
        "\n",
        "        self.file_col = file_col\n",
        "        self.gender_col = gender_col\n",
        "        self.race_col = race_col\n",
        "        self.transform = transform\n",
        "\n",
        "        try:\n",
        "            self.labels_df = pd.read_csv(label_file)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Label file not found at {label_file}\")\n",
        "            self.labels_df = pd.DataFrame()\n",
        "            return\n",
        "\n",
        "        # 라벨 인코딩(항상 정렬)\n",
        "        self.gender_map = {label: i for i, label in enumerate(sorted(self.labels_df[self.gender_col].unique()))}\n",
        "        self.race_map   = {label: i for i, label in enumerate(sorted(self.labels_df[self.race_col].unique()))}\n",
        "\n",
        "        self.idx_to_gender = {v: k for k, v in self.gender_map.items()}\n",
        "        self.idx_to_race   = {v: k for k, v in self.race_map.items()}\n",
        "\n",
        "        print(f\"Dataset loaded from {label_file}. Number of samples: {len(self.labels_df)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def _resolve_img_path(self, fname: str) -> Path:\n",
        "        \"\"\"CSV의 file 값에 'train/' 또는 'val/' 포함 여부에 따라 안전하게 경로 생성\"\"\"\n",
        "        f = str(fname).lstrip(\"/\\\\\")\n",
        "        if f.startswith((\"train/\", \"val/\")):\n",
        "            return (self.data_root / f).resolve()\n",
        "        return (self.img_root / f).resolve()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.item()\n",
        "\n",
        "        row = self.labels_df.iloc[idx]\n",
        "        img_path = self._resolve_img_path(row[self.file_col])\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except FileNotFoundError:\n",
        "            # 누락 파일은 다음 샘플로 스킵\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "        # 라벨\n",
        "        gender = self.gender_map[row[self.gender_col]]\n",
        "        race   = self.race_map[row[self.race_col]]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'gender': torch.tensor(gender, dtype=torch.long),\n",
        "            'race':   torch.tensor(race,   dtype=torch.long),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded from ./data/fairface/fairface_label_train.csv. Number of samples: 86744\n",
            "Dataset loaded from ./data/fairface/fairface_label_val.csv. Number of samples: 10954\n",
            "\n",
            "DataLoaders created.\n",
            "Train dataset size: 86744\n",
            "Validation dataset size: 10954\n",
            "Sample batch shape: torch.Size([32, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# === 1.4 데이터 변환 및 데이터로더 생성 ===\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# CPU에서 먼저 파이프라인 확인 시 Augmentation을 최소화해도 좋음\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "}\n",
        "\n",
        "if os.path.exists(TRAIN_LABEL_FILE) and os.path.exists(VAL_LABEL_FILE):\n",
        "    image_datasets = {\n",
        "        'train': FairFaceDataset(\n",
        "            img_root=TRAIN_IMG_DIR, label_file=TRAIN_LABEL_FILE,\n",
        "            file_col=\"file\", gender_col=\"gender\", race_col=\"race\",\n",
        "            transform=data_transforms['train']\n",
        "        ),\n",
        "        'val': FairFaceDataset(\n",
        "            img_root=VAL_IMG_DIR, label_file=VAL_LABEL_FILE,\n",
        "            file_col=\"file\", gender_col=\"gender\", race_col=\"race\",\n",
        "            transform=data_transforms['val']\n",
        "        )\n",
        "    }\n",
        "\n",
        "    # 빠른 확인용 서브셋 옵션\n",
        "    train_ds = image_datasets['train']\n",
        "    val_ds   = image_datasets['val']\n",
        "    if FAST_DEBUG:\n",
        "        train_ds = Subset(train_ds, list(range(min(DEBUG_SAMPLES_TRAIN, len(train_ds)))))\n",
        "        val_ds   = Subset(val_ds,   list(range(min(DEBUG_SAMPLES_VAL,   len(val_ds)))))\n",
        "\n",
        "    dataloaders = {\n",
        "        'train': DataLoader(\n",
        "            train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "            num_workers=NUM_WORKERS, persistent_workers=False\n",
        "        ),\n",
        "        'val': DataLoader(\n",
        "            val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "            num_workers=NUM_WORKERS, persistent_workers=False\n",
        "        )\n",
        "    }\n",
        "\n",
        "    dataset_sizes = {split: len(dataloaders[split].dataset) for split in ['train', 'val']}\n",
        "    print(\"\\nDataLoaders created.\")\n",
        "    print(f\"Train dataset size: {dataset_sizes['train']}\")\n",
        "    print(f\"Validation dataset size: {dataset_sizes['val']}\")\n",
        "\n",
        "    # 한 배치만 꺼내 모양 확인\n",
        "    batch = next(iter(dataloaders['train']))\n",
        "    print(f\"Sample batch shape: {batch['image'].shape}\")\n",
        "else:\n",
        "    print(\"\\nError: Could not create DataLoaders.\")\n",
        "    print(\"Please ensure the label files exist at the specified paths and re-run this cell.\")\n",
        "    dataloaders = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 단계 2: Baseline 모델 구축 및 학습\n",
        "\n",
        "이제 데이터 준비가 완료되었으니, 사전 학습된 ResNet18 모델을 기반으로 Baseline 모델을 구축하고 FairFace 데이터셋으로 fine-tuning을 진행합니다.\n",
        "\n",
        "**수행 작업:**\n",
        "1.  **모델 정의**: ImageNet으로 사전 학습된 ResNet18 모델을 불러온 후, 우리의 예측 목표(성별 또는 인종 분류)에 맞게 마지막 출력 레이어를 수정합니다.\n",
        "2.  **학습 함수 정의**: 모델을 지정된 에폭(epoch) 동안 학습하고, 매 에폭마다 검증 데이터셋으로 성능을 평가하는 `train_model` 함수를 정의합니다. 이 함수는 가장 성능이 좋았던 모델의 가중치를 저장합니다.\n",
        "3.  **모델 학습 실행**: 정의된 함수와 데이터로더를 사용하여 실제로 모델 학습을 시작합니다. 학습 과정에서의 손실(loss)과 정확도(accuracy)가 출력됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and helper functions are defined.\n",
            "You can now run the next cell to start training the baseline model.\n"
          ]
        }
      ],
      "source": [
        "# === 2.1 모델 정의 및 학습/평가 함수 ===\n",
        "\n",
        "def get_model(num_classes, pretrained=True):\n",
        "    \"\"\"\n",
        "    사전 학습된 ResNet18 모델을 로드하고 fine-tuning을 위해 마지막 레이어를 수정합니다.\n",
        "    \"\"\"\n",
        "    weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "    model = models.resnet18(weights=weights)\n",
        "    \n",
        "    # 마지막 레이어를 제외한 모든 파라미터를 동결 (Feature Extractor로 사용)\n",
        "    if pretrained:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "    # 마지막 Fully Connected Layer를 새로운 레이어로 교체\n",
        "    # 이 새로운 레이어의 파라미터는 기본적으로 requires_grad=True 입니다.\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    \n",
        "    return model.to(DEVICE)\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, dataloaders, num_epochs=10):\n",
        "    \"\"\"모델 학습 및 검증을 위한 메인 루프\"\"\"\n",
        "    since = time.time()\n",
        "    \n",
        "    # 학습 과정의 손실 및 정확도를 기록할 딕셔너리\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # 각 에폭은 학습과 검증 단계를 거칩니다.\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # tqdm을 사용하여 진행 상황을 시각화합니다.\n",
        "            for batch in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\"):\n",
        "                inputs = batch['image'].to(DEVICE)\n",
        "                labels = batch[TARGET_ATTR].to(DEVICE)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "            \n",
        "            # history에 기록\n",
        "            history[f'{phase}_loss'].append(epoch_loss)\n",
        "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
        "\n",
        "            # 검증 단계에서 최고 성능 모델 저장\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "                print(f\"** Best validation accuracy updated: {best_acc:.4f}, Model saved to {MODEL_SAVE_PATH}\")\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"학습 과정의 손실과 정확도 변화를 시각화합니다.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    ax1.plot(history['train_loss'], label='Train Loss')\n",
        "    ax1.plot(history['val_loss'], label='Validation Loss')\n",
        "    ax1.set_title('Model Loss')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(history['train_acc'], label='Train Accuracy')\n",
        "    ax2.plot(history['val_acc'], label='Validation Accuracy')\n",
        "    ax2.set_title('Model Accuracy')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'baseline_training_history.png'))\n",
        "    plt.show()\n",
        "\n",
        "print(\"Model and helper functions are defined.\")\n",
        "print(\"You can now run the next cell to start training the baseline model.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline model initialized for 2 classes.\n",
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a027822029849be883efc5e64213279",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Phase:   0%|          | 0/2711 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6324 Acc: 0.6429\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6c9857897cd43a989d4b04b7e4f4a6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val Phase:   0%|          | 0/343 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6120 Acc: 0.6766\n",
            "** Best validation accuracy updated: 0.6766, Model saved to best_baseline_model.pth\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cd99e827d8c47099f6d5cc10efaed23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Phase:   0%|          | 0/2711 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6203 Acc: 0.6561\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ededabc343ff4f7090cf7c3f6ea8fd39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val Phase:   0%|          | 0/343 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.5559 Acc: 0.7091\n",
            "** Best validation accuracy updated: 0.7091, Model saved to best_baseline_model.pth\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78d21d74b1954108854f061212bb7f4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Phase:   0%|          | 0/2711 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6196 Acc: 0.6576\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87ec99a9e0cb4758b3c1f27486b65ce1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val Phase:   0%|          | 0/343 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.5628 Acc: 0.7069\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2cced8b1e7b47d1a3598151217714aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Phase:   0%|          | 0/2711 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6230 Acc: 0.6564\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f503cc5abfe148bf8f14c51568b5b0eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val Phase:   0%|          | 0/343 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.5690 Acc: 0.6938\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8bf065d3adb4cf29974828f7e32e381",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Phase:   0%|          | 0/2711 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6197 Acc: 0.6581\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2e736eb31c8433493e288ced9fd8a49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val Phase:   0%|          | 0/343 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.5555 Acc: 0.7114\n",
            "** Best validation accuracy updated: 0.7114, Model saved to best_baseline_model.pth\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e221d2334dfc4e75896fe80f11b888a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Phase:   0%|          | 0/2711 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# === 2.2 Baseline 모델 학습 실행 ===\n",
        "\n",
        "# 데이터로더가 성공적으로 생성되었는지 확인\n",
        "if dataloaders:\n",
        "    # train dataset 참조\n",
        "    train_ds = dataloaders['train'].dataset\n",
        "    # Subset일 경우 원본 Dataset으로 접근\n",
        "    if isinstance(train_ds, torch.utils.data.Subset):\n",
        "        train_ds = train_ds.dataset\n",
        "\n",
        "    # 타겟 속성에 따른 클래스 수 계산\n",
        "    if TARGET_ATTR == \"gender\":\n",
        "        num_classes = len(train_ds.gender_map)\n",
        "    elif TARGET_ATTR == \"race\":\n",
        "        num_classes = len(train_ds.race_map)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown TARGET_ATTR: {TARGET_ATTR}\")\n",
        "\n",
        "    # 모델 초기화\n",
        "    baseline_model = get_model(num_classes=num_classes, pretrained=True)\n",
        "    print(f\"Baseline model initialized for {num_classes} classes.\")\n",
        "\n",
        "    # 손실 함수 정의\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 옵티마이저 정의 (fc 레이어만 학습)\n",
        "    optimizer = optim.SGD(baseline_model.fc.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "    # 모델 학습 시작\n",
        "    baseline_model, history = train_model(\n",
        "        baseline_model, criterion, optimizer, dataloaders, num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "\n",
        "    # 학습 결과 시각화\n",
        "    print(\"\\nPlotting training history...\")\n",
        "    plot_training_history(history)\n",
        "\n",
        "else:\n",
        "    print(\"Dataloaders are not available. Cannot start training.\")\n",
        "    print(\"Please go back to cell 1.4 and ensure the dataset is loaded correctly.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### 단계 2.3: Baseline 모델 성능 및 공정성 평가\n",
        "\n",
        "모델 학습이 완료되었습니다. 이제 검증 데이터셋(validation set)을 사용하여 학습된 모델의 전반적인 성능과 그룹별 공정성 지표를 평가합니다.\n",
        "\n",
        "**수행 작업:**\n",
        "1.  **평가 함수 정의**: 모델의 예측을 받아 전체 정확도, 그룹별 정확도, 그리고 간단한 공정성 지표(정확도 차이, SPD)를 계산하는 함수를 정의합니다.\n",
        "2.  **성능 평가 실행**: 저장된 베스트 모델을 불러와 검증 데이터셋에 대한 예측을 수행하고, 위 함수를 사용해 결과를 분석합니다.\n",
        "3.  **결과 시각화**: 그룹별 성능 차이를 막대그래프로 시각화하여 편향성을 직관적으로 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 2.3 성능 및 공정성 평가 함수 정의 및 실행 ===\n",
        "\n",
        "def evaluate_fairness(model, dataloader, criterion):\n",
        "    \"\"\"모델의 성능과 공정성 지표를 상세히 평가하고 결과를 반환합니다.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    y_true, y_pred, sensitive_attrs = [], [], []\n",
        "    \n",
        "    # 평가 과정에서는 기울기를 계산할 필요가 없습니다.\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            inputs = batch['image'].to(DEVICE)\n",
        "            labels = batch[TARGET_ATTR].to(DEVICE)\n",
        "            s_attrs = batch[SENSITIVE_ATTR].to(DEVICE)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            sensitive_attrs.extend(s_attrs.cpu().numpy())\n",
        "\n",
        "    # 결과를 numpy 배열로 변환\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    sensitive_attrs = np.array(sensitive_attrs)\n",
        "    \n",
        "    # --- 지표 계산 ---\n",
        "    results = {}\n",
        "    \n",
        "    # 1. 전체 성능\n",
        "    results['overall_loss'] = running_loss / len(dataloader.dataset)\n",
        "    results['overall_acc'] = np.mean(y_true == y_pred)\n",
        "    \n",
        "    # 2. 그룹별 성능\n",
        "    group_accuracies = {}\n",
        "    group_sizes = {}\n",
        "    \n",
        "    # 민감 속성의 인덱스-이름 맵 가져오기\n",
        "    s_map = dataloader.dataset.dataset.idx_to_race if SENSITIVE_ATTR == 'race' else dataloader.dataset.dataset.idx_to_gender\n",
        "    \n",
        "    for group_idx, group_name in s_map.items():\n",
        "        mask = (sensitive_attrs == group_idx)\n",
        "        if mask.sum() > 0:\n",
        "            group_accuracies[group_name] = np.mean(y_true[mask] == y_pred[mask])\n",
        "            group_sizes[group_name] = mask.sum()\n",
        "    \n",
        "    results['group_accuracies'] = group_accuracies\n",
        "    results['group_sizes'] = group_sizes\n",
        "    \n",
        "    # 3. 공정성 지표\n",
        "    if group_accuracies:\n",
        "        max_acc = max(group_accuracies.values())\n",
        "        min_acc = min(group_accuracies.values())\n",
        "        results['accuracy_gap'] = max_acc - min_acc # 최대 정확도 차이\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "def plot_fairness_results(results):\n",
        "    \"\"\"공정성 평가 결과를 시각화합니다.\"\"\"\n",
        "    group_accuracies = results['group_accuracies']\n",
        "    group_names = list(group_accuracies.keys())\n",
        "    acc_values = list(group_accuracies.values())\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    bars = plt.bar(group_names, acc_values, color=sns.color_palette('viridis', len(group_names)))\n",
        "    \n",
        "    plt.title('Baseline Model Accuracy by Sensitive Group', fontsize=16)\n",
        "    plt.xlabel('Sensitive Attribute Group', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    \n",
        "    # 막대 위에 정확도 수치 표시\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')\n",
        "        \n",
        "    # 전체 정확도와 정확도 차이를 그래프에 텍스트로 추가\n",
        "    plt.axhline(y=results['overall_acc'], color='r', linestyle='--', label=f\"Overall Acc: {results['overall_acc']:.3f}\")\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'baseline_fairness_evaluation.png'))\n",
        "    plt.show()\n",
        "\n",
        "# === 평가 실행 ===\n",
        "if dataloaders:\n",
        "    # 가장 성능이 좋았던 모델 가중치를 다시 로드\n",
        "    num_classes = len(label_maps[TARGET_ATTR])\n",
        "    model_to_evaluate = get_model(num_classes, pretrained=False)\n",
        "    \n",
        "    try:\n",
        "        model_to_evaluate.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(f\"Model loaded from {MODEL_SAVE_PATH} for evaluation.\")\n",
        "\n",
        "        # 평가 실행\n",
        "        baseline_results = evaluate_fairness(model_to_evaluate, dataloaders['val'], criterion)\n",
        "\n",
        "        # 결과 출력\n",
        "        print(\"\\n--- Baseline Model Evaluation Results ---\")\n",
        "        print(f\"Overall Accuracy: {baseline_results['overall_acc']:.4f}\")\n",
        "        print(f\"Overall Loss: {baseline_results['overall_loss']:.4f}\")\n",
        "        print(\"\\nGroup Accuracies:\")\n",
        "        for group, acc in baseline_results['group_accuracies'].items():\n",
        "            print(f\"  - {group}: {acc:.4f} (n={baseline_results['group_sizes'][group]})\")\n",
        "        print(f\"\\nMaximum Accuracy Gap: {baseline_results.get('accuracy_gap', 0):.4f}\")\n",
        "        \n",
        "        # 결과 시각화\n",
        "        plot_fairness_results(baseline_results)\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Saved model not found at {MODEL_SAVE_PATH}. Please run the training cell first.\")\n",
        "else:\n",
        "    print(\"Dataloaders not available. Cannot run evaluation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 단계 3: Micro-Bias Sensitivity Curve (편향 민감도 곡선) 분석\n",
        "\n",
        "Baseline 모델의 성능 평가를 마쳤습니다. 이제 이 모델이 데이터셋의 미세한 편향 변화에 얼마나 민감하게 반응하는지를 측정합니다.\n",
        "\n",
        "**실험 목표:**\n",
        "\"데이터가 전반적으로 공정해 보여도, 특정 그룹의 비율이 아주 약간만 변해도 모델의 예측이 크게 영향을 받는가?\"라는 질문에 답하는 것입니다. 이를 통해 모델의 안정성과 잠재적 편향성을 더 깊이 이해할 수 있습니다.\n",
        "\n",
        "**수행 작업:**\n",
        "1.  **편향 주입 샘플러(`BiasedSampler`) 정의**: 검증 데이터셋에서 특정 그룹(예: 'White' 인종) 내의 특정 클래스(예: 'Male' 성별) 비율을 원하는 만큼 정밀하게 조절하여 데이터를 추출하는 커스텀 `Sampler`를 정의합니다.\n",
        "2.  **민감도 분석 실행**: 편향 비율을 단계적으로(예: 40% -> 60%) 변화시키면서, 각 단계마다 편향이 주입된 데이터로 모델을 평가합니다. 전체 정확도, 그룹별 정확도, 공정성 지표(SPD)의 변화를 기록합니다.\n",
        "3.  **결과 시각화**: X축을 '주입된 편향의 강도', Y축을 '성능 및 공정성 지표'로 하는 \"편향 민감도 곡선\"을 그려, 변화의 추이를 직관적으로 분석합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 3.1 편향 주입 샘플러 및 민감도 분석 실행 ===\n",
        "\n",
        "# --- 실험 설정 ---\n",
        "# 'White' 그룹 내 'Male'의 비율을 바꿔나갑니다.\n",
        "BIAS_INJECTION_GROUP = 'White' \n",
        "BIAS_INJECTION_TARGET = 'Male'\n",
        "# 비율을 0.4 (40%) 에서 0.7 (70%) 까지 0.05 (5%) 단위로 변경\n",
        "BIAS_STEPS = np.arange(0.4, 0.75, 0.05) \n",
        "\n",
        "\n",
        "class BiasedSampler(Sampler):\n",
        "    \"\"\"데이터셋에서 특정 하위 그룹의 비율을 의도적으로 조절하는 샘플러\"\"\"\n",
        "    def __init__(self, dataset, target_group_name, target_class_name, desired_class_ratio_in_group):\n",
        "        self.dataset = dataset\n",
        "        self.target_group_idx = dataset.race_map[target_group_name]\n",
        "        self.target_class_idx = dataset.gender_map[target_class_name]\n",
        "        self.desired_ratio = desired_class_ratio_in_group\n",
        "\n",
        "        df = self.dataset.labels_df\n",
        "        \n",
        "        # 1. 목표 그룹('White')에 해당하는 인덱스\n",
        "        self.group_indices = df[df[SENSITIVE_ATTR] == target_group_name].index\n",
        "        \n",
        "        # 2. 목표 그룹 내에서, 목표 클래스('Male')인 인덱스와 아닌 인덱스\n",
        "        self.target_class_in_group_indices = df.loc[self.group_indices][df[TARGET_ATTR] == target_class_name].index.tolist()\n",
        "        self.other_class_in_group_indices = df.loc[self.group_indices][df[TARGET_ATTR] != target_class_name].index.tolist()\n",
        "        \n",
        "        # 3. 목표 그룹이 아닌 나머지 모든 인덱스\n",
        "        self.other_group_indices = df.index.drop(self.group_indices).tolist()\n",
        "\n",
        "        # 4. 목표 그룹('White')의 전체 샘플 수\n",
        "        self.num_group_samples = len(self.group_indices)\n",
        "        \n",
        "        # 5. 목표 그룹 내에서 목표 클래스('Male')가 차지해야 할 샘플 수 계산\n",
        "        self.num_target_class_samples = int(self.num_group_samples * self.desired_ratio)\n",
        "        self.num_other_class_samples = self.num_group_samples - self.num_target_class_samples\n",
        "        \n",
        "    def __iter__(self):\n",
        "        # 목표 그룹 내에서 원하는 비율만큼 클래스 샘플링 (복원 추출)\n",
        "        target_samples = np.random.choice(self.target_class_in_group_indices, self.num_target_class_samples, replace=True)\n",
        "        other_class_samples = np.random.choice(self.other_class_in_group_indices, self.num_other_class_samples, replace=True)\n",
        "        \n",
        "        # 샘플 인덱스를 합침: (목표그룹 내 Male 샘플 + 목표그룹 내 Female 샘플) + 나머지 그룹 샘플\n",
        "        final_indices = np.concatenate([target_samples, other_class_samples, self.other_group_indices])\n",
        "        np.random.shuffle(final_indices)\n",
        "        \n",
        "        return iter(final_indices.tolist())\n",
        "\n",
        "    def __len__(self):\n",
        "        # 데이터셋의 전체 길이는 변하지 않음\n",
        "        return len(self.dataset.labels_df)\n",
        "\n",
        "\n",
        "def run_sensitivity_analysis(model, dataset):\n",
        "    \"\"\"편향 비율을 바꿔가며 민감도 분석을 실행하고 결과를 반환\"\"\"\n",
        "    results_list = []\n",
        "    \n",
        "    # 이전에 학습된 모델을 사용하므로, 평가 모드로 설정\n",
        "    model.eval()\n",
        "    \n",
        "    for ratio in tqdm(BIAS_STEPS, desc=\"Analyzing Bias Sensitivity\"):\n",
        "        # 편향이 주입된 데이터로 평가\n",
        "        sampler = BiasedSampler(dataset, BIAS_INJECTION_GROUP, BIAS_INJECTION_TARGET, ratio)\n",
        "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS)\n",
        "        \n",
        "        # 평가 함수 재사용\n",
        "        eval_results = evaluate_fairness(model, dataloader, nn.CrossEntropyLoss())\n",
        "        eval_results['bias_ratio'] = ratio\n",
        "        results_list.append(eval_results)\n",
        "        \n",
        "    return pd.DataFrame(results_list)\n",
        "\n",
        "# --- 분석 실행 ---\n",
        "if 'baseline_model' in locals() and baseline_model is not None:\n",
        "    print(\"Starting Micro-Bias Sensitivity Analysis...\")\n",
        "    # 분석에는 검증(validation) 데이터셋을 사용합니다.\n",
        "    sensitivity_results_df = run_sensitivity_analysis(baseline_model, image_datasets['val'])\n",
        "    print(\"Analysis finished.\")\n",
        "    \n",
        "    # 결과 확인\n",
        "    display(sensitivity_results_df[['bias_ratio', 'overall_acc', 'accuracy_gap']].head())\n",
        "else:\n",
        "    print(\"Baseline model not trained or available. Please run Step 2 first.\")\n",
        "    sensitivity_results_df = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 3.2 편향 민감도 곡선 시각화 ===\n",
        "\n",
        "if sensitivity_results_df is not None:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "    fig.suptitle(f\"Micro-Bias Sensitivity Curve\\n(Injecting bias into '{BIAS_INJECTION_GROUP}' group)\", fontsize=16)\n",
        "\n",
        "    # --- 그래프 1: 정확도 변화 ---\n",
        "    ax1.plot(sensitivity_results_df['bias_ratio'], sensitivity_results_df['overall_acc'], \n",
        "             marker='o', linestyle='-', label='Overall Accuracy', linewidth=2.5)\n",
        "    \n",
        "    # 그룹별 정확도 변화도 함께 표시\n",
        "    group_acc_df = sensitivity_results_df['group_accuracies'].apply(pd.Series)\n",
        "    for group in group_acc_df.columns:\n",
        "        ax1.plot(sensitivity_results_df['bias_ratio'], group_acc_df[group], \n",
        "                 marker='.', linestyle='--', label=f'Accuracy ({group})')\n",
        "\n",
        "    ax1.set_xlabel(f\"Proportion of '{BIAS_INJECTION_TARGET}' class in '{BIAS_INJECTION_GROUP}' group\")\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_title('Accuracy vs. Injected Bias')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, which='both', linestyle='--')\n",
        "\n",
        "    # --- 그래프 2: 공정성 지표(정확도 갭) 변화 ---\n",
        "    ax2.plot(sensitivity_results_df['bias_ratio'], sensitivity_results_df['accuracy_gap'], \n",
        "             marker='o', linestyle='-', color='r', label='Max Accuracy Gap')\n",
        "    \n",
        "    ax2.set_xlabel(f\"Proportion of '{BIAS_INJECTION_TARGET}' class in '{BIAS_INJECTION_GROUP}' group\")\n",
        "    ax2.set_ylabel('Max Accuracy Gap (Higher is worse)')\n",
        "    ax2.set_title('Fairness Metric vs. Injected Bias')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, which='both', linestyle='--')\n",
        "    \n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'micro_bias_sensitivity_curve.png'))\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Sensitivity analysis results are not available. Please run the previous cell first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 단계 4: Over-Correction Damage Index (ODI, 과보정 피해 지수) 분석\n",
        "\n",
        "편향 완화 기법은 공정성을 높이는 데 도움이 되지만, 종종 모델의 전반적인 성능(정확도)을 하락시키는 Trade-off 관계를 가집니다. 특히 편향이 크지 않은 데이터셋에 과도한 완화 기법을 적용하면, 공정성은 약간 개선되는 반면 성능은 크게 저하될 수 있습니다.\n",
        "\n",
        "**실험 목표:**\n",
        "ODI는 **\"편향 감소 1단위당 발생하는 성능 손실량\"**을 정량화한 지표입니다. 이 지표를 통해 편향 완화 기법 적용의 효율성을 평가하고, '과보정'으로 인한 불필요한 성능 저하 리스크를 측정합니다.\n",
        "\n",
        "**수행 작업:**\n",
        "1.  **편향 완화 기법 적용 (Reweighing)**: 학습 데이터셋에서 소수 그룹에 더 높은 가중치를 부여하여 편향을 완화하는 `Reweighing` 기법을 적용합니다. 이를 위해 그룹별 가중치를 계산하고, 가중치가 적용된 `WeightedRandomSampler`를 사용해 모델을 재학습합니다.\n",
        "2.  **완화 모델 평가**: Reweighing이 적용된 모델의 성능과 공정성 지표를 Baseline 모델과 동일한 방식으로 평가합니다.\n",
        "3.  **ODI 계산 및 비교**: Baseline 모델과 완화 모델의 성능(정확도) 및 공정성(정확도 갭) 변화량을 측정하고, 이를 바탕으로 ODI를 계산하여 완화 기법의 효율성을 분석합니다.\n",
        "    -   **ODI = (Accuracy 감소량) / (Accuracy Gap 감소량)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 4.1 Reweighing 기법 적용 및 ODI 계산 ===\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "# --- 1. Reweighing을 위한 가중치 계산 ---\n",
        "print(\"--- Step 1: Calculating weights for Reweighing ---\")\n",
        "\n",
        "# 학습 데이터셋의 라벨 정보를 가져옵니다.\n",
        "train_df = image_datasets['train'].dataset.labels_df.iloc[image_datasets['train'].indices]\n",
        "\n",
        "# 민감 속성(SENSITIVE_ATTR)의 그룹별 데이터 수를 계산합니다.\n",
        "group_counts = train_df[SENSITIVE_ATTR].value_counts()\n",
        "num_samples = len(train_df)\n",
        "\n",
        "# 각 그룹에 대한 가중치 계산: (전체 샘플 수 / (그룹 수 * 해당 그룹의 샘플 수))\n",
        "# 이 방식은 소수 그룹에 더 높은 가중치를 부여합니다.\n",
        "group_weights = {group: num_samples / (len(group_counts) * count) for group, count in group_counts.items()}\n",
        "\n",
        "print(\"Group counts in training data:\\n\", group_counts)\n",
        "print(\"\\nCalculated group weights for sampling:\\n\", group_weights)\n",
        "\n",
        "# 학습 데이터셋의 각 샘플에 대한 가중치를 할당합니다.\n",
        "sample_weights = train_df[SENSITIVE_ATTR].apply(lambda group: group_weights[group]).to_numpy()\n",
        "sample_weights = torch.from_numpy(sample_weights).double()\n",
        "\n",
        "# WeightedRandomSampler 생성\n",
        "# 이 샘플러는 각 샘플이 뽑힐 확률을 `sample_weights`에 따라 조절합니다.\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "# 가중치가 적용된 새로운 학습 데이터로더 생성\n",
        "reweighed_train_loader = DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS)\n",
        "\n",
        "# (검증 데이터로더는 변경 없음)\n",
        "reweighed_dataloaders = {'train': reweighed_train_loader, 'val': dataloaders['val']}\n",
        "print(\"\\nCreated a new train dataloader with WeightedRandomSampler.\")\n",
        "\n",
        "\n",
        "# --- 2. Reweighing 모델 재학습 ---\n",
        "print(\"\\n--- Step 2: Retraining model with Reweighing ---\")\n",
        "\n",
        "# 새로운 모델을 처음부터 다시 학습시킵니다.\n",
        "num_classes = len(label_maps[TARGET_ATTR])\n",
        "reweighed_model = get_model(num_classes=num_classes, pretrained=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(reweighed_model.fc.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "# 재학습 실행 (함수 재사용)\n",
        "reweighed_model, reweighed_history = train_model(\n",
        "    reweighed_model, criterion, optimizer, reweighed_dataloaders, num_epochs=NUM_EPOCHS\n",
        ")\n",
        "\n",
        "\n",
        "# --- 3. 완화 모델 평가 및 ODI 계산 ---\n",
        "print(\"\\n--- Step 3: Evaluating mitigated model and calculating ODI ---\")\n",
        "\n",
        "# 재학습된 모델 평가\n",
        "reweighed_results = evaluate_fairness(reweighed_model, dataloaders['val'], criterion)\n",
        "\n",
        "print(\"\\n--- Reweighed Model Evaluation Results ---\")\n",
        "print(f\"Overall Accuracy: {reweighed_results['overall_acc']:.4f}\")\n",
        "print(\"Group Accuracies:\")\n",
        "for group, acc in reweighed_results['group_accuracies'].items():\n",
        "    print(f\"  - {group}: {acc:.4f}\")\n",
        "print(f\"Maximum Accuracy Gap: {reweighed_results.get('accuracy_gap', 0):.4f}\")\n",
        "\n",
        "\n",
        "# ODI 계산\n",
        "# (Accuracy 감소량) / (Accuracy Gap 감소량)\n",
        "accuracy_drop = baseline_results['overall_acc'] - reweighed_results['overall_acc']\n",
        "fairness_gain = baseline_results['accuracy_gap'] - reweighed_results['accuracy_gap']\n",
        "\n",
        "# 분모가 0이거나 매우 작은 경우 (편향 개선이 거의 없음) ODI 계산이 불안정해지므로 처리\n",
        "if fairness_gain > 1e-6:\n",
        "    odi = accuracy_drop / fairness_gain\n",
        "else:\n",
        "    odi = float('inf') # 편향 개선이 없으면 비용은 무한대로 간주\n",
        "\n",
        "print(\"\\n--- Over-Correction Damage Index (ODI) ---\")\n",
        "print(f\"Baseline Accuracy: {baseline_results['overall_acc']:.4f}\")\n",
        "print(f\"Reweighed Accuracy: {reweighed_results['overall_acc']:.4f}\")\n",
        "print(f\"  -> Accuracy Drop: {accuracy_drop:.4f}\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"Baseline Accuracy Gap: {baseline_results['accuracy_gap']:.4f}\")\n",
        "print(f\"Reweighed Accuracy Gap: {reweighed_results['accuracy_gap']:.4f}\")\n",
        "print(f\"  -> Fairness Gain (Gap Reduction): {fairness_gain:.4f}\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"ODI (Accuracy Drop / Fairness Gain): {odi:.4f}\")\n",
        "\n",
        "if odi > 1.0:\n",
        "    print(\"Interpretation: ODI > 1.0. The drop in overall accuracy is GREATER than the gain in fairness.\")\n",
        "    print(\"This suggests a potentially inefficient trade-off (over-correction).\")\n",
        "elif odi >= 0:\n",
        "    print(\"Interpretation: 0 <= ODI <= 1.0. The drop in overall accuracy is LESS than or equal to the gain in fairness.\")\n",
        "    print(\"This suggests a potentially efficient trade-off.\")\n",
        "else:\n",
        "    print(\"Interpretation: ODI < 0. Both accuracy and fairness have improved (ideal case).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 단계 5: Hidden Subgroup Discovery (잠복 하위집단 탐지)\n",
        "\n",
        "지금까지의 분석은 `race`나 `gender`와 같이 단일 속성을 기준으로 편향성을 측정했습니다. 하지만 편향은 여러 속성이 교차하는 더 작은 하위집단(subgroup)에서 증폭되어 나타날 수 있습니다. 예를 들어, 모델이 '흑인 여성' 또는 '동아시아인 남성'과 같이 특정 인종과 성별이 조합된 그룹에서만 유독 낮은 성능을 보일 수 있습니다.\n",
        "\n",
        "**실험 목표:**\n",
        "전체 평균이나 단일 그룹별 지표에서는 드러나지 않는 '잠복 편향'을 찾아내는 것입니다. 이를 위해 두 가지 이상의 속성을 조합하여 가능한 모든 하위집단을 만들고, 각 집단에서의 성능을 측정하여 가장 취약한 그룹(worst-performing subgroup)을 식별합니다.\n",
        "\n",
        "**수행 작업:**\n",
        "1.  **전체 예측 결과 생성**: Baseline 모델을 사용하여 검증 데이터셋의 모든 샘플에 대한 예측값과 실제값, 그리고 각 샘플의 속성(성별, 인종 등)을 하나의 데이터프레임으로 통합합니다.\n",
        "2.  **하위집단별 성능 분석**: `race`와 `gender`를 조합하여 생성된 모든 하위집단(예: White-Male, White-Female, Black-Male, ...)에 대해 정확도를 계산합니다.\n",
        "3.  **결과 시각화 및 분석**: 하위집단별 정확도를 막대그래프로 시각화하고, 전체 평균 정확도와 비교하여 성능이 가장 낮은 최악의 하위집단을 식별합니다. 이를 통해 모델이 어떤 특정 그룹에 취약한지 명확히 파악합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 5.1 잠복 하위집단 분석 실행 ===\n",
        "\n",
        "def get_predictions_for_subgroup_analysis(model, dataloader):\n",
        "    \"\"\"데이터셋 전체에 대한 예측을 수행하고, 라벨 및 속성과 함께 데이터프레임으로 반환합니다.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    y_true, y_pred, genders, races = [], [], [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Getting predictions for subgroup analysis\"):\n",
        "            inputs = batch['image'].to(DEVICE)\n",
        "            \n",
        "            # 예측 대상 속성에 따른 실제 라벨\n",
        "            true_labels = batch[TARGET_ATTR].cpu().numpy()\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            _, pred_labels = torch.max(outputs, 1)\n",
        "            pred_labels = pred_labels.cpu().numpy()\n",
        "            \n",
        "            # 모든 속성 정보 저장\n",
        "            y_true.extend(true_labels)\n",
        "            y_pred.extend(pred_labels)\n",
        "            genders.extend(batch['gender'].cpu().numpy())\n",
        "            races.extend(batch['race'].cpu().numpy())\n",
        "            \n",
        "    # 숫자 인덱스를 다시 문자열 라벨로 변환\n",
        "    idx_to_gender = dataloader.dataset.dataset.idx_to_gender\n",
        "    idx_to_race = dataloader.dataset.dataset.idx_to_race\n",
        "    \n",
        "    # 예측 대상 속성에 따라 y_true와 y_pred를 문자열로 변환\n",
        "    if TARGET_ATTR == 'gender':\n",
        "        true_labels_str = [idx_to_gender[i] for i in y_true]\n",
        "        pred_labels_str = [idx_to_gender[i] for i in y_pred]\n",
        "    else: # race\n",
        "        true_labels_str = [idx_to_race[i] for i in y_true]\n",
        "        pred_labels_str = [idx_to_race[i] for i in y_pred]\n",
        "\n",
        "    # 결과 데이터프레임 생성\n",
        "    df = pd.DataFrame({\n",
        "        'true_label': true_labels_str,\n",
        "        'predicted_label': pred_labels_str,\n",
        "        'gender': [idx_to_gender[i] for i in genders],\n",
        "        'race': [idx_to_race[i] for i in races]\n",
        "    })\n",
        "    \n",
        "    df['correct'] = (df['true_label'] == df['predicted_label'])\n",
        "    \n",
        "    return df\n",
        "\n",
        "# --- 분석 실행 ---\n",
        "if 'baseline_model' in locals() and baseline_model is not None:\n",
        "    # 1. 전체 예측 결과 생성\n",
        "    predictions_df = get_predictions_for_subgroup_analysis(baseline_model, dataloaders['val'])\n",
        "\n",
        "    # 2. 하위집단(race x gender)별 정확도 계산\n",
        "    subgroup_analysis = predictions_df.groupby(['race', 'gender']).agg(\n",
        "        accuracy=('correct', 'mean'),\n",
        "        count=('correct', 'size')\n",
        "    ).reset_index()\n",
        "\n",
        "    # 정확도를 기준으로 정렬\n",
        "    subgroup_analysis = subgroup_analysis.sort_values(by='accuracy', ascending=True)\n",
        "\n",
        "    print(\"\\n--- Hidden Subgroup Analysis Results (Race x Gender) ---\")\n",
        "    display(subgroup_analysis)\n",
        "\n",
        "    # 3. 결과 시각화\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    \n",
        "    # 하위집단 이름을 'race-gender' 형태로 만듭니다.\n",
        "    subgroup_analysis['subgroup'] = subgroup_analysis['race'] + '-' + subgroup_analysis['gender']\n",
        "    \n",
        "    bars = sns.barplot(x='accuracy', y='subgroup', data=subgroup_analysis, palette='plasma')\n",
        "    \n",
        "    plt.title('Hidden Subgroup Performance (Race x Gender)', fontsize=16)\n",
        "    plt.xlabel('Accuracy', fontsize=12)\n",
        "    plt.ylabel('Subgroup', fontsize=12)\n",
        "    plt.xlim(0, 1.0)\n",
        "    \n",
        "    # 전체 평균 정확도를 수직선으로 표시\n",
        "    overall_acc = predictions_df['correct'].mean()\n",
        "    plt.axvline(x=overall_acc, color='r', linestyle='--', label=f'Overall Accuracy ({overall_acc:.3f})')\n",
        "    \n",
        "    # 막대 옆에 수치 표시\n",
        "    for p in bars.patches:\n",
        "        width = p.get_width()\n",
        "        plt.text(width + 0.01, p.get_y() + p.get_height() / 2.,\n",
        "                 f'{width:.3f}', va='center')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'hidden_subgroup_analysis.png'))\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Baseline model not trained or available. Please run Step 2 first.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
